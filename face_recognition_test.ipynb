{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdnur/cvpr_23_24_spring/blob/main/face_recognition_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "F9Blksj4Ngh5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjYKZsAQNlCd",
        "outputId": "37067110-f681-4e04-e09e-619d0e8507f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQzYkod6Z15X",
        "outputId": "596f5245-2f4d-49e3-a4f5-9003ec710abf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: ['MOHAMMAD BIN AB JALIL SHEAKH', 'MD IMTIAJ ALAM SAJIN', 'IMAM HASAN JAMI', 'TAHMID AL RAFID SIDDIQUE', 'ESM-E MOULA CHOWDHURY ABHA', 'FAIZA BINTE ZAMAN', 'MD ATIK ULLAH KHAN', 'MD TAREK MAHMUD', 'NAVID MAHFUZ NAYEEM', 'SRABONE RAXIT', 'RAHAD-UL-ISLAM RABBY', 'REZWAN AHMAD', 'SHEIKH AKIB ALMAS', 'SYEDA HUMAIRA JABEEN', 'MD SHANZID HASAN', 'BISHANATH TARAFDER', 'MD JAHID HASSAN', 'MD NAIMUR RAHMAN', 'FAHIM RAHMAN', 'AL-NAFI', 'MD FARDIN AMIN RIYAD', 'MD TOYABUR RAHAMAN', 'S M FAISAL', 'ABDULLAH AL SHAHRIAR', 'MOHAMMAD NUR', 'NAFIS MUBASSHIR SHAH', 'TAHFIM IBN KHAN', 'SATYAJIT DAS', 'AHMED IMTIAZ', 'MD WAHIDUZZAMAN SUVA', 'NAHAR ISLAM NISHI', 'MD ABU ZAYED KHAN', 'MD SAJID ISLAM KHAN', 'TARIKUL ISLAM NISHAT', 'MOHAMMED TANVIR HASSAN', 'SADAT BIN MASUD', 'MD MUNTASIR AREFIN NAEEM']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing MOHAMMAD BIN AB JALIL SHEAKH - Train: 100%|██████████| 6/6 [00:06<00:00,  1.05s/it]\n",
            "Processing MOHAMMAD BIN AB JALIL SHEAKH - Validation: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n",
            "Processing MOHAMMAD BIN AB JALIL SHEAKH - Test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]\n",
            "Processing MD IMTIAJ ALAM SAJIN - Train: 100%|██████████| 20/20 [00:09<00:00,  2.09it/s]\n",
            "Processing MD IMTIAJ ALAM SAJIN - Validation: 100%|██████████| 5/5 [00:03<00:00,  1.62it/s]\n",
            "Processing MD IMTIAJ ALAM SAJIN - Test: 100%|██████████| 7/7 [00:03<00:00,  2.25it/s]\n",
            "Processing IMAM HASAN JAMI - Train: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n",
            "Processing IMAM HASAN JAMI - Validation: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
            "Processing IMAM HASAN JAMI - Test: 100%|██████████| 3/3 [00:02<00:00,  1.00it/s]\n",
            "Processing TAHMID AL RAFID SIDDIQUE - Train: 100%|██████████| 13/13 [00:12<00:00,  1.06it/s]\n",
            "Processing TAHMID AL RAFID SIDDIQUE - Validation: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]\n",
            "Processing TAHMID AL RAFID SIDDIQUE - Test: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing ESM-E MOULA CHOWDHURY ABHA - Train: 100%|██████████| 17/17 [00:04<00:00,  3.46it/s]\n",
            "Processing ESM-E MOULA CHOWDHURY ABHA - Validation: 100%|██████████| 4/4 [00:01<00:00,  2.93it/s]\n",
            "Processing ESM-E MOULA CHOWDHURY ABHA - Test: 100%|██████████| 7/7 [00:02<00:00,  2.50it/s]\n",
            "Processing FAIZA BINTE ZAMAN - Train: 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]\n",
            "Processing FAIZA BINTE ZAMAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n",
            "Processing FAIZA BINTE ZAMAN - Test: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n",
            "Processing MD ATIK ULLAH KHAN - Train: 100%|██████████| 16/16 [00:08<00:00,  1.87it/s]\n",
            "Processing MD ATIK ULLAH KHAN - Validation: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n",
            "Processing MD ATIK ULLAH KHAN - Test: 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
            "Processing MD TAREK MAHMUD - Train: 100%|██████████| 12/12 [00:06<00:00,  1.83it/s]\n",
            "Processing MD TAREK MAHMUD - Validation: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
            "Processing MD TAREK MAHMUD - Test: 100%|██████████| 5/5 [00:02<00:00,  1.94it/s]\n",
            "Processing NAVID MAHFUZ NAYEEM - Train: 100%|██████████| 12/12 [00:13<00:00,  1.09s/it]\n",
            "Processing NAVID MAHFUZ NAYEEM - Validation: 100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\n",
            "Processing NAVID MAHFUZ NAYEEM - Test: 100%|██████████| 4/4 [00:04<00:00,  1.19s/it]\n",
            "Processing SRABONE RAXIT - Train: 100%|██████████| 12/12 [00:06<00:00,  1.97it/s]\n",
            "Processing SRABONE RAXIT - Validation: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
            "Processing SRABONE RAXIT - Test: 100%|██████████| 5/5 [00:03<00:00,  1.37it/s]\n",
            "Processing RAHAD-UL-ISLAM RABBY - Train: 100%|██████████| 23/23 [00:21<00:00,  1.07it/s]\n",
            "Processing RAHAD-UL-ISLAM RABBY - Validation: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n",
            "Processing RAHAD-UL-ISLAM RABBY - Test: 100%|██████████| 8/8 [00:08<00:00,  1.00s/it]\n",
            "Processing REZWAN AHMAD - Train: 100%|██████████| 6/6 [00:02<00:00,  2.63it/s]\n",
            "Processing REZWAN AHMAD - Validation: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
            "Processing REZWAN AHMAD - Test: 100%|██████████| 3/3 [00:01<00:00,  1.96it/s]\n",
            "Processing SHEIKH AKIB ALMAS - Train: 100%|██████████| 12/12 [00:03<00:00,  3.05it/s]\n",
            "Processing SHEIKH AKIB ALMAS - Validation: 100%|██████████| 3/3 [00:00<00:00,  3.80it/s]\n",
            "Processing SHEIKH AKIB ALMAS - Test: 100%|██████████| 5/5 [00:01<00:00,  3.37it/s]\n",
            "Processing SYEDA HUMAIRA JABEEN - Train: 100%|██████████| 6/6 [00:02<00:00,  2.31it/s]\n",
            "Processing SYEDA HUMAIRA JABEEN - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
            "Processing SYEDA HUMAIRA JABEEN - Test: 100%|██████████| 3/3 [00:00<00:00,  3.46it/s]\n",
            "Processing MD SHANZID HASAN - Train: 100%|██████████| 12/12 [00:04<00:00,  3.00it/s]\n",
            "Processing MD SHANZID HASAN - Validation: 100%|██████████| 3/3 [00:00<00:00,  3.59it/s]\n",
            "Processing MD SHANZID HASAN - Test: 100%|██████████| 5/5 [00:01<00:00,  2.83it/s]\n",
            "Processing BISHANATH TARAFDER - Train: 100%|██████████| 5/5 [00:02<00:00,  2.44it/s]\n",
            "Processing BISHANATH TARAFDER - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
            "Processing BISHANATH TARAFDER - Test: 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]\n",
            "Processing MD JAHID HASSAN - Train: 100%|██████████| 6/6 [00:01<00:00,  3.20it/s]\n",
            "Processing MD JAHID HASSAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s]\n",
            "Processing MD JAHID HASSAN - Test: 100%|██████████| 3/3 [00:00<00:00,  3.94it/s]\n",
            "Processing MD NAIMUR RAHMAN - Train: 100%|██████████| 6/6 [00:03<00:00,  1.53it/s]\n",
            "Processing MD NAIMUR RAHMAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "Processing MD NAIMUR RAHMAN - Test: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]\n",
            "Processing FAHIM RAHMAN - Train: 100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n",
            "Processing FAHIM RAHMAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "Processing FAHIM RAHMAN - Test: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
            "Processing AL-NAFI - Train: 100%|██████████| 7/7 [00:02<00:00,  2.60it/s]\n",
            "Processing AL-NAFI - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
            "Processing AL-NAFI - Test: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]\n",
            "Processing MD FARDIN AMIN RIYAD - Train: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s]\n",
            "Processing MD FARDIN AMIN RIYAD - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "Processing MD FARDIN AMIN RIYAD - Test: 100%|██████████| 4/4 [00:02<00:00,  1.70it/s]\n",
            "Processing MD TOYABUR RAHAMAN - Train: 100%|██████████| 12/12 [00:03<00:00,  3.31it/s]\n",
            "Processing MD TOYABUR RAHAMAN - Validation: 100%|██████████| 3/3 [00:00<00:00,  3.36it/s]\n",
            "Processing MD TOYABUR RAHAMAN - Test: 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]\n",
            "Processing S M FAISAL - Train: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n",
            "Processing S M FAISAL - Validation: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
            "Processing S M FAISAL - Test: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]\n",
            "Processing ABDULLAH AL SHAHRIAR - Train: 100%|██████████| 12/12 [00:09<00:00,  1.22it/s]\n",
            "Processing ABDULLAH AL SHAHRIAR - Validation: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
            "Processing ABDULLAH AL SHAHRIAR - Test: 100%|██████████| 5/5 [00:03<00:00,  1.29it/s]\n",
            "Processing MOHAMMAD NUR - Train: 100%|██████████| 6/6 [00:04<00:00,  1.45it/s]\n",
            "Processing MOHAMMAD NUR - Validation: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n",
            "Processing MOHAMMAD NUR - Test: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]\n",
            "Processing NAFIS MUBASSHIR SHAH - Train: 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n",
            "Processing NAFIS MUBASSHIR SHAH - Validation: 100%|██████████| 3/3 [00:01<00:00,  1.56it/s]\n",
            "Processing NAFIS MUBASSHIR SHAH - Test: 100%|██████████| 4/4 [00:02<00:00,  1.34it/s]\n",
            "Processing TAHFIM IBN KHAN - Train: 100%|██████████| 12/12 [00:03<00:00,  3.06it/s]\n",
            "Processing TAHFIM IBN KHAN - Validation: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s]\n",
            "Processing TAHFIM IBN KHAN - Test: 100%|██████████| 5/5 [00:01<00:00,  3.02it/s]\n",
            "Processing SATYAJIT DAS - Train: 100%|██████████| 12/12 [00:06<00:00,  1.89it/s]\n",
            "Processing SATYAJIT DAS - Validation: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
            "Processing SATYAJIT DAS - Test: 100%|██████████| 5/5 [00:02<00:00,  2.28it/s]\n",
            "Processing AHMED IMTIAZ - Train: 100%|██████████| 23/23 [00:10<00:00,  2.21it/s]\n",
            "Processing AHMED IMTIAZ - Validation: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n",
            "Processing AHMED IMTIAZ - Test: 100%|██████████| 8/8 [00:04<00:00,  1.66it/s]\n",
            "Processing MD WAHIDUZZAMAN SUVA - Train: 100%|██████████| 25/25 [00:13<00:00,  1.91it/s]\n",
            "Processing MD WAHIDUZZAMAN SUVA - Validation: 100%|██████████| 6/6 [00:03<00:00,  1.97it/s]\n",
            "Processing MD WAHIDUZZAMAN SUVA - Test: 100%|██████████| 9/9 [00:03<00:00,  2.67it/s]\n",
            "Processing NAHAR ISLAM NISHI - Train: 100%|██████████| 12/12 [00:04<00:00,  2.81it/s]\n",
            "Processing NAHAR ISLAM NISHI - Validation: 100%|██████████| 3/3 [00:01<00:00,  2.01it/s]\n",
            "Processing NAHAR ISLAM NISHI - Test: 100%|██████████| 5/5 [00:01<00:00,  3.21it/s]\n",
            "Processing MD ABU ZAYED KHAN - Train: 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
            "Processing MD ABU ZAYED KHAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
            "Processing MD ABU ZAYED KHAN - Test: 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
            "Processing MD SAJID ISLAM KHAN - Train: 100%|██████████| 6/6 [00:01<00:00,  3.48it/s]\n",
            "Processing MD SAJID ISLAM KHAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
            "Processing MD SAJID ISLAM KHAN - Test: 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]\n",
            "Processing TARIKUL ISLAM NISHAT - Train: 100%|██████████| 7/7 [00:02<00:00,  2.79it/s]\n",
            "Processing TARIKUL ISLAM NISHAT - Validation: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
            "Processing TARIKUL ISLAM NISHAT - Test: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]\n",
            "Processing MOHAMMED TANVIR HASSAN - Train: 100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n",
            "Processing MOHAMMED TANVIR HASSAN - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "Processing MOHAMMED TANVIR HASSAN - Test: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
            "Processing SADAT BIN MASUD - Train: 100%|██████████| 6/6 [00:02<00:00,  2.44it/s]\n",
            "Processing SADAT BIN MASUD - Validation: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n",
            "Processing SADAT BIN MASUD - Test: 100%|██████████| 3/3 [00:00<00:00,  3.17it/s]\n",
            "Processing MD MUNTASIR AREFIN NAEEM - Train: 100%|██████████| 6/6 [00:03<00:00,  1.83it/s]\n",
            "Processing MD MUNTASIR AREFIN NAEEM - Validation: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "Processing MD MUNTASIR AREFIN NAEEM - Test: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 338\n",
            "Number of validation samples: 74\n",
            "Number of test samples: 147\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "TRAIN_DATA_DIR = '/content/drive/MyDrive/Training Data'\n",
        "IMG_SIZE = 227\n",
        "split_ratio = 0.8  # 80% training, 20% validation\n",
        "\n",
        "CATEGORIES = [folder for folder in os.listdir(TRAIN_DATA_DIR) if os.path.isdir(os.path.join(TRAIN_DATA_DIR, folder))]\n",
        "print(\"Categories:\", CATEGORIES)\n",
        "\n",
        "training_data = []\n",
        "test_data = []\n",
        "validation_data = []\n",
        "\n",
        "for c in CATEGORIES:\n",
        "    path = os.path.join(TRAIN_DATA_DIR, c)\n",
        "    class_num = CATEGORIES.index(c)\n",
        "\n",
        "    # List all images in the current category\n",
        "    img_files = os.listdir(path)\n",
        "\n",
        "    # Shuffle the list of images\n",
        "    random.shuffle(img_files)\n",
        "\n",
        "    # Split the data into train, validation, and test sets\n",
        "    num_samples = len(img_files)\n",
        "    num_train_samples = int(num_samples * split_ratio * 0.8)\n",
        "    num_valid_samples = int(num_samples * split_ratio * 0.2)\n",
        "\n",
        "    train_files = img_files[:num_train_samples]\n",
        "    valid_files = img_files[num_train_samples:num_train_samples + num_valid_samples]\n",
        "    test_files = img_files[num_train_samples + num_valid_samples:]\n",
        "\n",
        "    # Load and process training data\n",
        "    for img in tqdm(train_files, desc=f'Processing {c} - Train'):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img))\n",
        "            img_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            training_data.append([img_resized, class_num])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    # Load and process validation data\n",
        "    for img in tqdm(valid_files, desc=f'Processing {c} - Validation'):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img))\n",
        "            img_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            validation_data.append([img_resized, class_num])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    # Load and process test data\n",
        "    for img in tqdm(test_files, desc=f'Processing {c} - Test'):\n",
        "        try:\n",
        "            img_array = cv2.imread(os.path.join(path, img))\n",
        "            img_resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "            test_data.append([img_resized, class_num])\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "# Shuffle the data\n",
        "random.shuffle(training_data)\n",
        "random.shuffle(validation_data)\n",
        "random.shuffle(test_data)\n",
        "\n",
        "# Extract features (X) and labels (Y)\n",
        "X_train, Y_train = zip(*training_data)\n",
        "X_valid, Y_valid = zip(*validation_data)\n",
        "X_test, Y_test = zip(*test_data)\n",
        "\n",
        "# Convert to numpy arrays and reshape\n",
        "X_train = np.array(X_train).astype('float32').reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_train = np.array(Y_train)\n",
        "X_valid = np.array(X_valid).astype('float32').reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_valid = np.array(Y_valid)\n",
        "X_test = np.array(X_test).astype('float32').reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "# Print the number of samples in each set\n",
        "print(\"Number of training samples:\", len(training_data))\n",
        "print(\"Number of validation samples:\", len(validation_data))\n",
        "print(\"Number of test samples:\", len(test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AuuvuwxRVjU2"
      },
      "outputs": [],
      "source": [
        "# Save pickled data\n",
        "with open(\"/content/drive/MyDrive/X_train.pickle\", \"wb\") as pickle_out:\n",
        "    pickle.dump(X_train, pickle_out)\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Y_train.pickle\", \"wb\") as pickle_out:\n",
        "    pickle.dump(Y_train, pickle_out)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/X_valid.pickle\", \"wb\") as pickle_out:\n",
        "    pickle.dump(X_valid, pickle_out)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Y_valid.pickle\", \"wb\") as pickle_out:\n",
        "    pickle.dump(Y_valid, pickle_out)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/X_test.pickle\", \"wb\") as pickle_out:\n",
        "    pickle.dump(X_test, pickle_out)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Y_test.pickle\", \"wb\") as pickle_out:\n",
        "    pickle.dump(Y_test, pickle_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOHP0FsuNxoi",
        "outputId": "d34bf0bc-8f02-4afa-ee81-26bad2afcd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 55, 55, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 27, 27, 96)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 27, 27, 96)        384       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 17, 17, 256)       2973952   \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 17, 17, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 8, 8, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 8, 8, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 6, 6, 384)         885120    \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 6, 6, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_30 (Ba  (None, 6, 6, 384)         1536      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 4, 4, 384)         1327488   \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 4, 4, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_31 (Ba  (None, 4, 4, 384)         1536      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 2, 2, 256)         884992    \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 1, 1, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, 1, 1, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 4096)              1052672   \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, 4096)              16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, 4096)              16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 50)                204850    \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 50)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24183653 (92.25 MB)\n",
            "Trainable params: 24164517 (92.18 MB)\n",
            "Non-trainable params: 19136 (74.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ... (Your existing code for loading and splitting data)\n",
        "\n",
        "# Load pickled data\n",
        "pickle_in = open(\"/content/drive/MyDrive/X_train.pickle\", \"rb\")\n",
        "X_train = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/Y_train.pickle\", \"rb\")\n",
        "Y_train = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/X_valid.pickle\", \"rb\")\n",
        "X_valid = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/Y_valid.pickle\", \"rb\")\n",
        "Y_valid = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/X_test.pickle\", \"rb\")\n",
        "X_test = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(\"/content/drive/MyDrive/Y_test.pickle\", \"rb\")\n",
        "Y_test = pickle.load(pickle_in)\n",
        "\n",
        "# Calculate mean image for normalization\n",
        "mean_img = np.mean(X_train, axis=0)\n",
        "\n",
        "# Normalize the data\n",
        "X_train_norm, X_valid_norm, X_test_norm = X_train - mean_img, X_valid - mean_img, X_test - mean_img\n",
        "\n",
        "# Reshape training data\n",
        "X_train_norm = X_train_norm.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Define AlexNet model\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "\n",
        "    layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(filters=256, kernel_size=(11, 11), strides=(1, 1), padding='valid'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='valid'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='valid'),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(units=4096),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(units=4096),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    layers.Dense(50),\n",
        "    layers.Activation('sigmoid'),\n",
        "    layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',  # Update this line\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "W5QjHG6CV8ME"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_norm, Y_train,\n",
        "    epochs=10,\n",
        "    validation_data=(X_valid_norm, Y_valid),\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3ngLN1mWBCr",
        "outputId": "5f5a7a31-f6d7-4eb8-8348-f12ec99d7cae"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 138s 5s/step - loss: -2.0112 - accuracy: 0.0592 - val_loss: 70.1676 - val_accuracy: 0.0135\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 55s 5s/step - loss: -39.7750 - accuracy: 0.0651 - val_loss: 67.8788 - val_accuracy: 0.0135\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 56s 5s/step - loss: -47.3730 - accuracy: 0.0473 - val_loss: 65.0707 - val_accuracy: 0.0135\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 56s 5s/step - loss: -54.5865 - accuracy: 0.0444 - val_loss: 62.2101 - val_accuracy: 0.0135\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 52s 5s/step - loss: -65.5287 - accuracy: 0.0414 - val_loss: 59.6283 - val_accuracy: 0.0135\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 54s 5s/step - loss: -69.7476 - accuracy: 0.0444 - val_loss: 57.5594 - val_accuracy: 0.0135\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 54s 5s/step - loss: -73.0708 - accuracy: 0.0355 - val_loss: 52.6475 - val_accuracy: 0.0135\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 54s 5s/step - loss: -83.1595 - accuracy: 0.0355 - val_loss: 48.0779 - val_accuracy: 0.0135\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 54s 5s/step - loss: -91.7730 - accuracy: 0.0355 - val_loss: 14.3394 - val_accuracy: 0.0405\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 54s 5s/step - loss: -96.7877 - accuracy: 0.0444 - val_loss: 15.6413 - val_accuracy: 0.0270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "pvnO50WiqdRB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "2b9228e8-1e00-415f-fdde-fe58866a4e5e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-82f14ad0308e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `history` is the variable containing the training history\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI51dG36c18k"
      },
      "outputs": [],
      "source": [
        "# Evaluate on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
        "print('\\nTest Accuracy:', test_acc)\n",
        "print('Test Loss:', test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "a909GUNXdA48"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "# Function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "# Function to convert OpenCV Rectangle bounding box image into base64 byte string\n",
        "def bbox_to_bytes(bbox_array):\n",
        "    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    bbox_PIL.save(iobuf, format='png')\n",
        "    bbox_bytes = 'data:image/png;base64,{}'.format(str(b64encode(iobuf.getvalue()), 'utf-8'))\n",
        "    return bbox_bytes\n",
        "\n",
        "# Initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CCqMVTqWrhpu"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r54voRnWrn-M"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Function to preprocess the image for recognition\n",
        "def preprocess_for_recognition(img):\n",
        "    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img_resized = img_resized / 255.0\n",
        "    return np.expand_dims(img_resized, axis=0)\n",
        "\n",
        "# Function to mark attendance\n",
        "def mark_attendance(name):\n",
        "    print(f\"Marking attendance for {name}\")\n",
        "\n",
        "# Start streaming video from webcam\n",
        "video_stream()\n",
        "\n",
        "# Label for video\n",
        "label_html = 'Capturing...'\n",
        "\n",
        "# Initialize bounding box to empty\n",
        "bbox = ''\n",
        "\n",
        "# Dictionary to keep track of attendance\n",
        "attendance_record = {}\n",
        "\n",
        "# Delay between attendance markings (in seconds)\n",
        "attendance_delay = 5\n",
        "\n",
        "confidence_threshold = 0.7\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    bbox_array = np.zeros([480, 640, 4], dtype=np.uint8)\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face_roi = img[y:y+h, x:x+w]\n",
        "\n",
        "        face_for_recognition = preprocess_for_recognition(face_roi)\n",
        "\n",
        "        prediction = model.predict(face_for_recognition)\n",
        "        predicted_class_index = np.argmax(prediction)\n",
        "        confidence = prediction[0][predicted_class_index]\n",
        "        predicted_class = CATEGORIES[predicted_class_index]\n",
        "\n",
        "        if confidence > confidence_threshold and predicted_class not in attendance_record:\n",
        "            mark_attendance(predicted_class)\n",
        "            attendance_record[predicted_class] = True\n",
        "\n",
        "            time.sleep(attendance_delay)\n",
        "\n",
        "        bbox_array = cv2.rectangle(bbox_array, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        cv2.putText(bbox_array, f'{predicted_class} ({confidence:.2f})', (x + 2, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "    bbox_array[:, :, 3] = (bbox_array.max(axis=2) > 0).astype(int) * 255\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    bbox = bbox_bytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NWWlqrirslP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}